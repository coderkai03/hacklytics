{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Data Shape: (348, 4)\n",
      "Viral Data Shape: (46605, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>social_media_content</th>\n",
       "      <th>audio_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https：//www.tiktok.com/@geocaching/video/71648...</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>{\"total_faces\": 10, \"text_frames\": 1, \"screen_...</td>\n",
       "      <td>{\"quality_metrics\": {\"volume_level\": 0.0855373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https：//www.tiktok.com/@yoyobdt_/video/7253793...</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>{\"total_faces\": 57, \"text_frames\": 48, \"screen...</td>\n",
       "      <td>{\"quality_metrics\": {\"volume_level\": 0.1491330...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      video_filename   duration  \\\n",
       "0  https：//www.tiktok.com/@geocaching/video/71648...  12.666667   \n",
       "1  https：//www.tiktok.com/@yoyobdt_/video/7253793...  47.666667   \n",
       "\n",
       "                                social_media_content  \\\n",
       "0  {\"total_faces\": 10, \"text_frames\": 1, \"screen_...   \n",
       "1  {\"total_faces\": 57, \"text_frames\": 48, \"screen...   \n",
       "\n",
       "                                      audio_features  \n",
       "0  {\"quality_metrics\": {\"volume_level\": 0.0855373...  \n",
       "1  {\"quality_metrics\": {\"volume_level\": 0.1491330...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: Data Loading\n",
    "cv_data = pd.read_csv('results/tiktok_content_analysis.csv')\n",
    "viral_data = pd.read_csv('Viral Hooks Full Data Set.csv')\n",
    "\n",
    "print(\"CV Data Shape:\", cv_data.shape)\n",
    "print(\"Viral Data Shape:\", viral_data.shape)\n",
    "display(cv_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_filename</th>\n",
       "      <th>duration</th>\n",
       "      <th>social_media_content</th>\n",
       "      <th>audio_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.tiktok.com/@geocaching/video/71648...</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>{'total_faces': 10, 'text_frames': 1, 'screen_...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.0855373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.tiktok.com/@yoyobdt_/video/7253793...</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>{'total_faces': 57, 'text_frames': 48, 'screen...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.1491330...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.tiktok.com/@zebracat.ai/video/7446...</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>{'total_faces': 130, 'text_frames': 55, 'scree...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.0504763...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.tiktok.com/@travel/video/737835575...</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>{'total_faces': 6, 'text_frames': 10, 'screen_...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.1125932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.tiktok.com/@beepr_app/video/726991...</td>\n",
       "      <td>7.433333</td>\n",
       "      <td>{'total_faces': 0, 'text_frames': 8, 'screen_r...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.2917576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>https://www.tiktok.com/@thejerryapp/video/7253...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>{'total_faces': 206, 'text_frames': 40, 'scree...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.1882175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>https://www.tiktok.com/@bumble/video/735589792...</td>\n",
       "      <td>14.920000</td>\n",
       "      <td>{'total_faces': 20, 'text_frames': 5, 'screen_...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.2770988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>https://www.tiktok.com/@duolingo/video/7197477...</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>{'total_faces': 11, 'text_frames': 8, 'screen_...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.5891649...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>https://www.tiktok.com/@lingodeer.app/video/71...</td>\n",
       "      <td>17.866667</td>\n",
       "      <td>{'total_faces': 90, 'text_frames': 18, 'screen...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.1227528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>https://www.tiktok.com/@klook.my/video/7327622...</td>\n",
       "      <td>36.433333</td>\n",
       "      <td>{'total_faces': 40, 'text_frames': 34, 'screen...</td>\n",
       "      <td>{'quality_metrics': {'volume_level': 0.1595773...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        video_filename   duration  \\\n",
       "0    https://www.tiktok.com/@geocaching/video/71648...  12.666667   \n",
       "1    https://www.tiktok.com/@yoyobdt_/video/7253793...  47.666667   \n",
       "2    https://www.tiktok.com/@zebracat.ai/video/7446...  67.000000   \n",
       "3    https://www.tiktok.com/@travel/video/737835575...  14.200000   \n",
       "4    https://www.tiktok.com/@beepr_app/video/726991...   7.433333   \n",
       "..                                                 ...        ...   \n",
       "343  https://www.tiktok.com/@thejerryapp/video/7253...  40.000000   \n",
       "344  https://www.tiktok.com/@bumble/video/735589792...  14.920000   \n",
       "345  https://www.tiktok.com/@duolingo/video/7197477...   7.400000   \n",
       "346  https://www.tiktok.com/@lingodeer.app/video/71...  17.866667   \n",
       "347  https://www.tiktok.com/@klook.my/video/7327622...  36.433333   \n",
       "\n",
       "                                  social_media_content  \\\n",
       "0    {'total_faces': 10, 'text_frames': 1, 'screen_...   \n",
       "1    {'total_faces': 57, 'text_frames': 48, 'screen...   \n",
       "2    {'total_faces': 130, 'text_frames': 55, 'scree...   \n",
       "3    {'total_faces': 6, 'text_frames': 10, 'screen_...   \n",
       "4    {'total_faces': 0, 'text_frames': 8, 'screen_r...   \n",
       "..                                                 ...   \n",
       "343  {'total_faces': 206, 'text_frames': 40, 'scree...   \n",
       "344  {'total_faces': 20, 'text_frames': 5, 'screen_...   \n",
       "345  {'total_faces': 11, 'text_frames': 8, 'screen_...   \n",
       "346  {'total_faces': 90, 'text_frames': 18, 'screen...   \n",
       "347  {'total_faces': 40, 'text_frames': 34, 'screen...   \n",
       "\n",
       "                                        audio_features  \n",
       "0    {'quality_metrics': {'volume_level': 0.0855373...  \n",
       "1    {'quality_metrics': {'volume_level': 0.1491330...  \n",
       "2    {'quality_metrics': {'volume_level': 0.0504763...  \n",
       "3    {'quality_metrics': {'volume_level': 0.1125932...  \n",
       "4    {'quality_metrics': {'volume_level': 0.2917576...  \n",
       "..                                                 ...  \n",
       "343  {'quality_metrics': {'volume_level': 0.1882175...  \n",
       "344  {'quality_metrics': {'volume_level': 0.2770988...  \n",
       "345  {'quality_metrics': {'volume_level': 0.5891649...  \n",
       "346  {'quality_metrics': {'volume_level': 0.1227528...  \n",
       "347  {'quality_metrics': {'volume_level': 0.1595773...  \n",
       "\n",
       "[348 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Data Cleaning\n",
    "# Clean URLs\n",
    "cv_data['video_filename'] = cv_data['video_filename'].str.replace('⧸', '/')\n",
    "\n",
    "# Parse JSON helper function\n",
    "def parse_json_column(json_str):\n",
    "    if pd.isna(json_str):\n",
    "        return {}\n",
    "    try:\n",
    "        if isinstance(json_str, dict):\n",
    "            return json_str\n",
    "        if isinstance(json_str, str):\n",
    "            return json.loads(json_str.replace(\"'\", \"\\\"\"))\n",
    "        return {}\n",
    "    except:\n",
    "        print(f\"Failed to parse: {type(json_str)} - {str(json_str)[:100]}...\")\n",
    "        return {}\n",
    "\n",
    "# Reapply parsing\n",
    "cv_data['audio_features'] = cv_data['audio_features'].apply(parse_json_column)\n",
    "cv_data['social_media_content'] = cv_data['social_media_content'].apply(parse_json_column)\n",
    "cv_data['video_filename'] = cv_data['video_filename'].str.replace('：', ':').str.replace('⧸', '/').str.replace('.mp4', '')\n",
    "\n",
    "cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Apply transformation\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m cv_data \u001b[38;5;241m=\u001b[39m expand_features(cv_data)\n",
      "Cell \u001b[0;32mIn[57], line 12\u001b[0m, in \u001b[0;36mexpand_features\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Audio quality metrics\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[57], line 12\u001b[0m, in \u001b[0;36mexpand_features.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Audio quality metrics\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     14\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Extract features from social_media_content and audio_features\n",
    "def expand_features(df):\n",
    "    # Social media content features\n",
    "    df['total_faces'] = df['social_media_content'].apply(lambda x: x.get('total_faces', 0))\n",
    "    df['text_frames'] = df['social_media_content'].apply(lambda x: x.get('text_frames', 0))\n",
    "    df['screen_recording_frames'] = df['social_media_content'].apply(lambda x: x.get('screen_recording_frames', 0))\n",
    "    df['avg_faces_per_frame'] = df['social_media_content'].apply(lambda x: x.get('avg_faces_per_frame', 0))\n",
    "    df['text_percentage'] = df['social_media_content'].apply(lambda x: x.get('text_percentage', 0))\n",
    "    df['screen_recording_percentage'] = df['social_media_content'].apply(lambda x: x.get('screen_recording_percentage', 0))\n",
    "    \n",
    "    # Audio quality metrics\n",
    "    df['volume_level'] = df['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('volume_level', 0))\n",
    "    df['volume_consistency'] = df['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('volume_consistency', 0))\n",
    "    df['high_frequency_content'] = df['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('high_frequency_content', 0))\n",
    "    df['frequency_variation'] = df['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('frequency_variation', 0))\n",
    "    \n",
    "    # Audio dynamic analysis\n",
    "    df['dynamic_range'] = df['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('dynamic_range', 0))\n",
    "    df['peak_volume'] = df['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('peak_volume', 0))\n",
    "    df['median_volume'] = df['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('median_volume', 0))\n",
    "    df['noise_floor'] = df['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('noise_floor', 0))\n",
    "    \n",
    "    # Drop original columns\n",
    "    df = df.drop(['social_media_content', 'audio_features'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply transformation\n",
    "cv_data = expand_features(cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for null values\n",
    "# null_rows = cv_data[cv_data['audio_features'].isnull()]\n",
    "# print(\"\\nRows with null audio_features:\")\n",
    "# print(null_rows[['video_filename', 'audio_features']])\n",
    "\n",
    "# # Check for non-dict values\n",
    "# non_dict_rows = cv_data[cv_data['audio_features'].apply(lambda x: not isinstance(x, dict))]\n",
    "# print(\"\\nRows with non-dictionary audio_features:\")\n",
    "# print(non_dict_rows[['video_filename', 'audio_features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print first few rows of audio_features to see what we're dealing with\n",
    "# print(\"\\nFirst few audio_features values:\")\n",
    "# for i, af in enumerate(cv_data['audio_features'].head()):\n",
    "#     print(f\"\\nRow {i}:\")\n",
    "#     print(type(af))\n",
    "#     print(af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with None in audio_features:\n",
      "Index([], dtype='int64')\n",
      "\n",
      "Sample rows with None:\n"
     ]
    }
   ],
   "source": [
    "# Check for None values\n",
    "print(\"\\nRows with None in audio_features:\")\n",
    "print(cv_data[cv_data['audio_features'].isna()].index)\n",
    "\n",
    "# Print first few rows where audio_features is None\n",
    "print(\"\\nSample rows with None:\")\n",
    "bad_rows = cv_data[cv_data['audio_features'].isna()]\n",
    "if not bad_rows.empty:\n",
    "    print(bad_rows[['video_filename', 'audio_features']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Basic features\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Social media content features\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_frames\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces_per_frame\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces_per_frame\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Audio quality metrics\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Audio quality scores\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Audio dynamic analysis\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     30\u001b[0m     \n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m })\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[54], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Basic features\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Social media content features\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_frames\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces_per_frame\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces_per_frame\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscreen_recording_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     12\u001b[0m     \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Audio quality metrics\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Audio quality scores\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Audio dynamic analysis\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m     30\u001b[0m     \n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     32\u001b[0m })\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame({\n",
    "    # Basic features\n",
    "    'duration': cv_data['duration'],\n",
    "    \n",
    "    # Social media content features\n",
    "    'total_faces': cv_data['social_media_content'].apply(lambda x: x.get('total_faces', 0)),\n",
    "    'text_frames': cv_data['social_media_content'].apply(lambda x: x.get('text_frames', 0)),\n",
    "    'screen_recording_frames': cv_data['social_media_content'].apply(lambda x: x.get('screen_recording_frames', 0)),\n",
    "    'avg_faces_per_frame': cv_data['social_media_content'].apply(lambda x: x.get('avg_faces_per_frame', 0)),\n",
    "    'text_percentage': cv_data['social_media_content'].apply(lambda x: x.get('text_percentage', 0)),\n",
    "    'screen_recording_percentage': cv_data['social_media_content'].apply(lambda x: x.get('screen_recording_percentage', 0)),\n",
    "    \n",
    "    # Audio quality metrics\n",
    "    'volume_level': cv_data['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('volume_level', 0)),\n",
    "    'volume_consistency': cv_data['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('volume_consistency', 0)),\n",
    "    'high_frequency_content': cv_data['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('high_frequency_content', 0)),\n",
    "    'frequency_variation': cv_data['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('frequency_variation', 0)),\n",
    "    \n",
    "    # Audio quality scores\n",
    "    'volume_quality': cv_data['audio_features'].apply(lambda x: x.get('quality_scores', {}).get('volume_quality', 'unknown')),\n",
    "    'dynamic_range_quality': cv_data['audio_features'].apply(lambda x: x.get('quality_scores', {}).get('dynamic_range', 'unknown')),\n",
    "    'frequency_quality': cv_data['audio_features'].apply(lambda x: x.get('quality_scores', {}).get('frequency_quality', 'unknown')),\n",
    "    'overall_quality': cv_data['audio_features'].apply(lambda x: x.get('quality_scores', {}).get('overall_quality', 'unknown')),\n",
    "    \n",
    "    # Audio dynamic analysis\n",
    "    'dynamic_range': cv_data['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('dynamic_range', 0)),\n",
    "    'peak_volume': cv_data['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('peak_volume', 0)),\n",
    "    'median_volume': cv_data['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('median_volume', 0)),\n",
    "    'noise_floor': cv_data['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('noise_floor', 0)),\n",
    "    \n",
    "    'video_filename': cv_data['video_filename']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 4: Feature Engineering\u001b[39;00m\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Social media content features\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces_per_frame\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percent\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Quality metrics\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Dynamic analysis\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     21\u001b[0m     \n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Quality scores\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     27\u001b[0m     \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     29\u001b[0m })\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample video filename:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample social_media_content:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[50], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 4: Feature Engineering\u001b[39;00m\n\u001b[1;32m      2\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Social media content features\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_faces\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_faces_per_frame\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percent\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Quality metrics\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_level\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh_frequency_content\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_variation\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Dynamic analysis\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_volume\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_volume\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoise_floor\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     21\u001b[0m     \n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Quality scores\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_quality\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic_range\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrequency_quality\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality_scores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall_quality\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     27\u001b[0m     \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     29\u001b[0m })\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample video filename:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample social_media_content:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_media_content\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Cell 4: Feature Engineering\n",
    "features = pd.DataFrame({\n",
    "    'duration': cv_data['duration'],\n",
    "    'total_faces': cv_data['social_media_content'].apply(lambda x: x.get('total_faces', 0)),\n",
    "    'text_frames': cv_data['social_media_content'].apply(lambda x: x.get('text_frames', 0)),\n",
    "    'avg_faces': cv_data['social_media_content'].apply(lambda x: x.get('avg_faces_per_frame', 0)),\n",
    "    'text_percent': cv_data['social_media_content'].apply(lambda x: x.get('text_percentage', 0)),\n",
    "    'volume_level': cv_data['audio_features'].apply(lambda x: x.get('quality_metrics', {}).get('volume_level', 0)),\n",
    "    'dynamic_range': cv_data['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('dynamic_range', 0)),\n",
    "    'peak_volume': cv_data['audio_features'].apply(lambda x: x.get('dynamic_analysis', {}).get('peak_volume', 0)),\n",
    "    'video_filename': cv_data['video_filename']\n",
    "})\n",
    "\n",
    "print(\"\\nSample video filename:\", cv_data['video_filename'].iloc[0])\n",
    "print(\"\\nSample social_media_content:\", cv_data['social_media_content'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Merging\n",
    "full_data = pd.merge(\n",
    "    features,\n",
    "    viral_data[['ad_link', 'views', 'length']],\n",
    "    left_on='video_filename',\n",
    "    right_on='ad_link',\n",
    "    how='inner'\n",
    ").drop(columns=['video_filename', 'ad_link'])\n",
    "\n",
    "print(\"\\nMerged Data Shape:\", full_data.shape)\n",
    "full_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Train/Test Split\n",
    "X = full_data[['duration', 'total_faces', 'text_frames', 'avg_faces', \n",
    "              'text_percent', 'volume_level', 'dynamic_range', 'peak_volume', 'length']]\n",
    "y = full_data['views']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Model Training\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(f\"Training time: {time.time()-start_time:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Evaluation\n",
    "predictions = model.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:,.2f}\")\n",
    "print(f\"R²: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Save Model\n",
    "joblib.dump(model, 'models/view_predictor.pkl')\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Feature Importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(importance['feature'], importance['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
